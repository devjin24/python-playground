{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<1.22\n",
      "  Using cached numpy-1.21.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-learn<1.1\n",
      "  Using cached scikit_learn-1.0.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (10 kB)\n",
      "Collecting scipy==1.*\n",
      "  Using cached scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting matplotlib==3.*\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting theano\n",
      "  Using cached Theano-1.0.5-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy==1.*\n",
      "  Using cached scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "  Using cached scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.*)\n",
      "  Using cached contourpy-1.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.*)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.*)\n",
      "  Using cached fonttools-4.54.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.*)\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib==3.*\n",
      "  Using cached matplotlib-3.9.1.post1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib==3.*)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.*)\n",
      "  Using cached pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.*)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib==3.*)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting joblib>=0.11 (from scikit-learn<1.1)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.1)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting six>=1.9.0 (from theano)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.*)\n",
      "  Using cached contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Using cached scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl (29.8 MB)\n",
      "Using cached matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Using cached numpy-1.21.6-cp310-cp310-macosx_11_0_arm64.whl (12.4 MB)\n",
      "Using cached scikit_learn-1.0.2-cp310-cp310-macosx_12_0_arm64.whl (6.9 MB)\n",
      "Using cached contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl (244 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.54.1-cp310-cp310-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.7-cp310-cp310-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, six, pyparsing, pillow, packaging, numpy, kiwisolver, joblib, fonttools, cycler, scipy, python-dateutil, contourpy, theano, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.54.1 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.8.4 numpy-1.21.6 packaging-24.1 pillow-11.0.0 pyparsing-3.2.0 python-dateutil-2.9.0.post0 scikit-learn-1.0.2 scipy-1.11.4 six-1.16.0 theano-1.0.5 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<1.22\" \"scikit-learn<1.1\" \"scipy==1.*\" \"matplotlib==3.*\" theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 깃헙 참고\n",
    "https://github.com/unexploredtest/neural-networks-and-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:] ]\n",
    "        self.weights = [np.random.randn(y,x ) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "    \n",
    "    def SGD(self, training_data, epochs, mini_batch_size,eta, test_data=None):\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            time1 = time.time()\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            time2 = time.time()\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}, took {3:.2f} seconds\".format(\n",
    "                    j, self.evaluate(test_data), n_test, time2-time1))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete in {1:.2f} seconds\".format(j, time2-time1))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-sDAmbKVF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
